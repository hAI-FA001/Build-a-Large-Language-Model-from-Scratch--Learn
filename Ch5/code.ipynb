{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e67ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_len\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1429147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from generate_text import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_len'],\n",
    ")\n",
    "\n",
    "print(f\"Output:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7bda1",
   "metadata": {},
   "source": [
    "## Text Generation Loss\n",
    "Need to do same steps as `generate_text_simple` to compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ead2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                        [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [ \"effort moves you\",\n",
    "                        [1107,  588, 11311]]) #   \"really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609634c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5745dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      "tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs:\\n{token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c38218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a438cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# initial softmax probas corresponding to target tokens\n",
    "# we want to maximize these, to be close to 1\n",
    "\n",
    "text_idx = 0\n",
    "# select \"text_idx\" batch\n",
    "# select (i, targets[text_idx][i]) entry, the ith row and ith column\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "# each proba will be close to 1/50,257 initially\n",
    "print(f\"Text 1: {target_probas_1}\")\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(f\"Text 2: {target_probas_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e7d90",
   "metadata": {},
   "source": [
    "Steps for Loss: <br>\n",
    "Logits -> Probas -> Target Probas -> Log -> Average -> Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99bf21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# steps 1-3 are done\n",
    "\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c7b4d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f644838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = -1 * avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b68f84",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "The above steps calculated CE, which is implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43bab02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "852dcf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits: torch.Size([6, 50257])\n",
      "Flattened Targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # combine over the batch dimension\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(f\"Flattened Logits: {logits_flat.shape}\")\n",
    "print(f\"Flattened Targets: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fa94786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch performs all the steps\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dbd00",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "Measures how well the predicted proba distribution matches the actual distribution. <br>\n",
    "Can be understood as the effective vocabulary size the model is uncertain about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d09c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "print(torch.exp(loss))  # model is uncertain about 48725 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41afe41f",
   "metadata": {},
   "source": [
    "## Training/Validation Set Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84d04732",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd81fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_chars = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"Characters: {total_chars}\")\n",
    "print(f\"Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4868ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d02706e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M['context_len'],\n",
    "    stride=GPT_CONFIG_124M['context_len'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M['context_len'],\n",
    "    stride=GPT_CONFIG_124M['context_len'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e8ff5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Val Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "\n",
    "print(\"Train Loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nVal Loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dce81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ea7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f472ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 10.987583372328016\n",
      "Val Loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Val Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb323959",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f83754aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,\n",
    "                    train_loader, val_loader,\n",
    "                    optimizer, device, num_epochs,\n",
    "                    eval_freq, eval_iter,\n",
    "                    start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "            \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
    "        \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, max_new_tokens=50, context_size=context_size)\n",
    "    \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # compact print\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea2cf5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train Loss 9.781, Val Loss 9.933\n",
      "Ep 1 (Step 000005): Train Loss 8.111, Val Loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train Loss 6.661, Val Loss 7.048\n",
      "Ep 2 (Step 000015): Train Loss 5.961, Val Loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train Loss 5.726, Val Loss 6.600\n",
      "Ep 3 (Step 000025): Train Loss 5.201, Val Loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train Loss 4.417, Val Loss 6.278\n",
      "Ep 4 (Step 000035): Train Loss 4.069, Val Loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train Loss 3.732, Val Loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train Loss 2.850, Val Loss 6.179\n",
      "Ep 6 (Step 000050): Train Loss 2.427, Val Loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train Loss 2.104, Val Loss 6.134\n",
      "Ep 7 (Step 000060): Train Loss 1.882, Val Loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train Loss 1.320, Val Loss 6.238\n",
      "Ep 8 (Step 000070): Train Loss 0.985, Val Loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train Loss 0.717, Val Loss 6.293\n",
      "Ep 9 (Step 000080): Train Loss 0.541, Val Loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train Loss 0.391, Val Loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader,\n",
    "    optimizer, device, num_epochs,\n",
    "    eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c44c508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    f, ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label='Training Loss')\n",
    "    ax1.plot(epochs_seen, val_losses, label='Val Loss', linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only integer labels\n",
    "\n",
    "    ax2 = ax1.twiny()  # share the same Y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # invisible plot to align ticks\n",
    "    ax2.set_xlabel('Tokens Seen')\n",
    "\n",
    "    f.tight_layout()\n",
    "    plt.savefig('loss-plot.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f9ea949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2da0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
