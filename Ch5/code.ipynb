{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e67ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_len\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1429147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from generate_text import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_len'],\n",
    ")\n",
    "\n",
    "print(f\"Output:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7bda1",
   "metadata": {},
   "source": [
    "## Text Generation Loss\n",
    "Need to do same steps as `generate_text_simple` to compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ead2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                        [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [ \"effort moves you\",\n",
    "                        [1107,  588, 11311]]) #   \"really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609634c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5745dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      "tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs:\\n{token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c38218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a438cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# initial softmax probas corresponding to target tokens\n",
    "# we want to maximize these, to be close to 1\n",
    "\n",
    "text_idx = 0\n",
    "# select \"text_idx\" batch\n",
    "# select (i, targets[text_idx][i]) entry, the ith row and ith column\n",
    "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "# each proba will be close to 1/50,257 initially\n",
    "print(f\"Text 1: {target_probas_1}\")\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(f\"Text 2: {target_probas_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e7d90",
   "metadata": {},
   "source": [
    "Steps for Loss: <br>\n",
    "Logits -> Probas -> Target Probas -> Log -> Average -> Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bf21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# steps 1-3 are done\n",
    "\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7b4d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f644838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = -1 * avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b68f84",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss\n",
    "The above steps calculated CE, which is implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bab02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "852dcf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits: torch.Size([6, 50257])\n",
      "Flattened Targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # combine over the batch dimension\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(f\"Flattened Logits: {logits_flat.shape}\")\n",
    "print(f\"Flattened Targets: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa94786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch performs all the steps\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dbd00",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "Measures how well the predicted proba distribution matches the actual distribution. <br>\n",
    "Can be understood as the effective vocabulary size the model is uncertain about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca4d09c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "print(torch.exp(loss))  # model is uncertain about 48725 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41afe41f",
   "metadata": {},
   "source": [
    "## Training/Validation Set Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d04732",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd81fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_chars = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"Characters: {total_chars}\")\n",
    "print(f\"Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4868ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d02706e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M['context_len'],\n",
    "    stride=GPT_CONFIG_124M['context_len'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M['context_len'],\n",
    "    stride=GPT_CONFIG_124M['context_len'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e8ff5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Val Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "\n",
    "print(\"Train Loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nVal Loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dce81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08ea7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40f472ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 10.987583584255642\n",
      "Val Loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Val Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb323959",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f83754aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,\n",
    "                    train_loader, val_loader,\n",
    "                    optimizer, device, num_epochs,\n",
    "                    eval_freq, eval_iter,\n",
    "                    start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "            \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
    "        \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, max_new_tokens=50, context_size=context_size)\n",
    "    \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # compact print\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2cf5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train Loss 9.781, Val Loss 9.933\n",
      "Ep 1 (Step 000005): Train Loss 8.111, Val Loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train Loss 6.661, Val Loss 7.048\n",
      "Ep 2 (Step 000015): Train Loss 5.961, Val Loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train Loss 5.726, Val Loss 6.600\n",
      "Ep 3 (Step 000025): Train Loss 5.201, Val Loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train Loss 4.417, Val Loss 6.278\n",
      "Ep 4 (Step 000035): Train Loss 4.069, Val Loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train Loss 3.732, Val Loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train Loss 2.850, Val Loss 6.179\n",
      "Ep 6 (Step 000050): Train Loss 2.427, Val Loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train Loss 2.104, Val Loss 6.134\n",
      "Ep 7 (Step 000060): Train Loss 1.882, Val Loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train Loss 1.320, Val Loss 6.238\n",
      "Ep 8 (Step 000070): Train Loss 0.985, Val Loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train Loss 0.717, Val Loss 6.293\n",
      "Ep 9 (Step 000080): Train Loss 0.541, Val Loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train Loss 0.391, Val Loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader,\n",
    "    optimizer, device, num_epochs,\n",
    "    eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c44c508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    f, ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label='Training Loss')\n",
    "    ax1.plot(epochs_seen, val_losses, label='Val Loss', linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only integer labels\n",
    "\n",
    "    ax2 = ax1.twiny()  # share the same Y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # invisible plot to align ticks\n",
    "    ax2.set_xlabel('Tokens Seen')\n",
    "\n",
    "    f.tight_layout()\n",
    "    plt.savefig('loss-plot.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f9ea949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d9290",
   "metadata": {},
   "source": [
    "## Decoding Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ab2da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "# greedy decoding - selects token with highest proba, will generate same result each time\n",
    "token_ids = generate_text_simple(model, text_to_token_ids(\"Every effort moves you\", tokenizer), max_new_tokens=25, context_size=GPT_CONFIG_124M['context_len'])\n",
    "print(f\"Output:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf7356",
   "metadata": {},
   "source": [
    "### Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cbc43d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "#  probabilistic sampling, simple e.g\n",
    "\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# assume LLM generates these\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "# map logits back to token IDs\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f5d183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# replace with probabilistic sampling\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])  # same result, cuz this had the highest proba and will get selected most of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d21dc66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)  # other tokens are also sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16a71f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temp(logits, temp):\n",
    "    scaled = logits / temp\n",
    "    return torch.softmax(scaled, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63c76105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# less than 1 = higher confidence, sharper\n",
    "# more than 1 = more uniform\n",
    "\n",
    "temps = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temp(next_token_logits, temp) for temp in temps]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temps):\n",
    "    rects = ax.bar(x + i*bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Proba')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temp-plot.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd57b45",
   "metadata": {},
   "source": [
    "### Ex 5.1\n",
    "Sampling frequencies with temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3350e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 1\n",
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n",
      "\n",
      "Temperature: 0.1\n",
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n",
      "\n",
      "Temperature: 5\n",
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for T in temps:\n",
    "    print(f'Temperature: {T}')\n",
    "    print_sampled_tokens(softmax_with_temp(next_token_logits, T))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deba0d4",
   "metadata": {},
   "source": [
    "### Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a8dd0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(f\"Top Logits: {top_logits}\")\n",
    "print(f\"Top Positions: {top_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6411657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1], input=torch.tensor(float('-inf')), other=next_token_logits)\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0eeb6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "top_k_probas = torch.softmax(new_logits, dim=0)\n",
    "print(top_k_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26207c9",
   "metadata": {},
   "source": [
    "### Updated Text Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fb8ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        # stop generating earlier than max_new_tokens on end-of-sequence\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc79dda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_len'],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "\n",
    "print(f\"Output:\\n{token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b35e3",
   "metadata": {},
   "source": [
    "### Ex 5.2\n",
    "Different temperatures and top-k settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8834961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: T=100.0, K=1000\n",
      "Output:\n",
      "Every effort moves youoring myself usual sketchagged Em standingusingrolledura desirehouse fell canvor tone adopted coatoud why bedr et central simple\n",
      "\n",
      "Settings: T=1.0, K=1\n",
      "Output:\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n",
      "\n",
      "Settings: T=0.5, K=1\n",
      "Output:\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n",
      "\n",
      "Settings: T=2.0, K=5\n",
      "Output:\n",
      "Every effort moves you in the inevitable garlanded frame. The mere outline of the frame called up all Gisburn's an awful simpleton\n",
      "\n",
      "Settings: T=3.0, K=1000\n",
      "Output:\n",
      "Every effort moves you drawn HerBe myself full ago thisling Donng do again\"? genius across valuewing cheeks firstin mere did showbured\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import random\n",
    "\n",
    "temps = [0.1, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0, 100.0]\n",
    "top_k = [1, 5, 50, 100, 1000]\n",
    "\n",
    "# make 5 random combinations\n",
    "for T, K in random.choices(list(product(temps, top_k)), k=5):\n",
    "    print(f\"Settings: T={T}, K={K}\")\n",
    "    token_ids = generate(model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "            max_new_tokens=25, context_size=GPT_CONFIG_124M['context_len'],\n",
    "            temperature=T,\n",
    "            top_k=K)\n",
    "    print(f\"Output:\\n{token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \")}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4b551",
   "metadata": {},
   "source": [
    "### Ex 5.3\n",
    "Combination to force deterministic behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c83413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model, text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25, context_size=GPT_CONFIG_124M['context_len'],\n",
    "    # no scaling, choose top-1\n",
    "    # temperature=1.0, top_k=1,\n",
    "    # or exploit the code structure to not take the if-condition paths\n",
    "    temperature=0.0, top_k=None,\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f729d9",
   "metadata": {},
   "source": [
    "## Saving and Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcd01409",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46925bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c177abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save optimizer too, useful to resume training\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "}, \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eed6f557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore states\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1b856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
